{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malshi-Gimnadhi/-CPU-Scheduling-Algorithms-/blob/main/Handwritten%20English%20Letters%20Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'handwritten-characters:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F53376%2F101598%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240613%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240613T191947Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2097991ef2200c26a467c4c0942c5ab740f6427ba47f2975b0500023e7477878bde785e5754f70386efb660336960b4a1ddb8d5d1649e032cfe80776972fde6120c6611913bc9cf2eb924715730f0d6937878441116725ce6e48f7b99ea4783d87a8b0b6085a8ef8fa5ba80a104a494701ab88813d1b49e91322b13a4d375019ced2c70be4de51a9f23b219f8accade3e54edd00f8a94a2e05ff83b26b38d1aa093886bfe7e24066591278e07ca45820e30e6f3bf34fadfc84f717d052900a1910249ee7eb69e9520753c2af1de086be71f6bd30c6c5f69e981a5db3e2c7d8cf47dd79a65183ee8e3279ac648e877e0a3da76cd19133dfeae84b3f82e840df7f,handwriting-recognition:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F818027%2F1400106%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240613%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240613T191947Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da7ecddf1fab586ae9180b39125eec359a6f31ebb2f31f2fadc342f0a5b14a821d8d0c4aecd826b4e34f4a0f3f025fb329ac5edd354143eb9e51ae3b4b1e7c639432fc6d47f75f1abceb85fcbd8c148dc5a45cc351be8de6f45f43d8f22f30a0eefb1e5dfa7c5e7469ae38bca0d7acecab6b1476305a3964d851f76f59f4cf355326c7edb72ffe8b5b8e733c43d7e31e00bd7b67b6d7ae8a2a761c2e8afe0d118350557019084338e3cb97614f02ec1e7715d67f8a17a1a074852c070cd4221454fffb972d1b9d5377bda903e1e86750bcbf880c604f18937b9b8e78ea6332c86136411bc34a55d20211deb6e5b99ca1c154d54c31451c780be50487a9f045a98'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVkFCXQiCsEu",
        "outputId": "ec0a7e55-fc4e-4286-8673-84e4728b7756"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading handwritten-characters, 1740501298 bytes compressed\n",
            "[==================================================] 1740501298 bytes downloaded\n",
            "Downloaded and uncompressed: handwritten-characters\n",
            "Downloading handwriting-recognition, 1353071625 bytes compressed\n",
            "[==================================================] 1353071625 bytes downloaded\n",
            "Downloaded and uncompressed: handwriting-recognition\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "metadata": {
        "id": "ndo0pBseCsEv"
      },
      "cell_type": "markdown",
      "source": [
        "# *Offline Handwritten Text Recognition*\n",
        "\n",
        "### The purpose of this notebook is to give a brief idea and a basic approach for offline handwritten text recognition by using segmentation and classification."
      ]
    },
    {
      "metadata": {
        "id": "nv7dDU4zCsEw"
      },
      "cell_type": "markdown",
      "source": [
        "## What is Offline Handwritten Text Recognition?\n",
        "Offline handwriting recognition involves the automatic conversion of text in an image into letter codes that are usable within computer and text-processing applications. In simple terms, it is the text extraction from your handwritten notebooks/pages. Why called offline? The point being that there is an online text recognition system, which is referred for text that is digitally generated by using tools like stylus, apple pencil, etc."
      ]
    },
    {
      "metadata": {
        "id": "sm2lY_0kCsEx"
      },
      "cell_type": "markdown",
      "source": [
        "## Approach\n",
        "\n",
        "* **Step1** :  Build a digit(0-9) + A-Z characters classifier using a CNN architecture.\n",
        "* **Step2** :  Apply character segmentation for the handwritten word image.\n",
        "* **Step3** :  Classify each segmented letter and then get the final word in the image."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLPV_6d0CsEx",
        "outputId": "bb804b00-8174-4fbd-a2af-0302fb311d86"
      },
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNpn_U0QCsEx",
        "outputId": "d79a2bc4-d7ce-4f92-c514-b59bad526c61"
      },
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install keras tensorflow numpy pandas scikit-learn matplotlib seaborn opencv-python-headless\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import imutils\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Activation, Flatten, Dense, MaxPooling2D, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.82)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3eQ76WGCCsEx"
      },
      "cell_type": "code",
      "source": [
        "dir = \"../input/handwritten-characters/Train/\"\n",
        "train_data = []\n",
        "img_size = 32\n",
        "non_chars = [\"#\",\"$\",\"&\",\"@\"]\n",
        "for i in os.listdir(dir):\n",
        "    if i in non_chars:\n",
        "        continue\n",
        "    count = 0\n",
        "    sub_directory = os.path.join(dir,i)\n",
        "    for j in os.listdir(sub_directory):\n",
        "        count+=1\n",
        "        if count > 4000:\n",
        "            break\n",
        "        img = cv2.imread(os.path.join(sub_directory,j),0)\n",
        "        img = cv2.resize(img,(img_size,img_size))\n",
        "        train_data.append([img,i])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVheLTHDCsEx",
        "outputId": "749ce1e8-c59b-4885-80b7-e09c4680f196"
      },
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "raJadKn7CsEy"
      },
      "cell_type": "code",
      "source": [
        "val_dir = \"../input/handwritten-characters/Validation/\"\n",
        "val_data = []\n",
        "img_size = 32\n",
        "for i in os.listdir(val_dir):\n",
        "    if i in non_chars:\n",
        "        continue\n",
        "    count = 0\n",
        "    sub_directory = os.path.join(val_dir,i)\n",
        "    for j in os.listdir(sub_directory):\n",
        "        count+=1\n",
        "        if count > 1000:\n",
        "            break\n",
        "        img = cv2.imread(os.path.join(sub_directory,j),0)\n",
        "        img = cv2.resize(img,(img_size,img_size))\n",
        "        val_data.append([img,i])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doqaXmLcCsEy",
        "outputId": "50cc73df-1375-4e1c-f57e-b3c3b4847be8"
      },
      "cell_type": "code",
      "source": [
        "len(val_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15209"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "npVgn_qMCsEy"
      },
      "cell_type": "code",
      "source": [
        "random.shuffle(train_data)\n",
        "random.shuffle(val_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "f89yibDlCsEy"
      },
      "cell_type": "code",
      "source": [
        "train_X = []\n",
        "train_Y = []\n",
        "for features,label in train_data:\n",
        "    train_X.append(features)\n",
        "    train_Y.append(label)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "002upVlQCsEz"
      },
      "cell_type": "code",
      "source": [
        "val_X = []\n",
        "val_Y = []\n",
        "for features,label in val_data:\n",
        "    val_X.append(features)\n",
        "    val_Y.append(label)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ewd23Kc4CsEz"
      },
      "cell_type": "code",
      "source": [
        "LB = LabelBinarizer()\n",
        "train_Y = LB.fit_transform(train_Y)\n",
        "val_Y = LB.fit_transform(val_Y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oNIEhcytCsEz"
      },
      "cell_type": "code",
      "source": [
        "train_X = np.array(train_X)/255.0\n",
        "train_X = train_X.reshape(-1,32,32,1)\n",
        "train_Y = np.array(train_Y)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9pB58Y_ECsEz"
      },
      "cell_type": "code",
      "source": [
        "val_X = np.array(val_X)/255.0\n",
        "val_X = val_X.reshape(-1,32,32,1)\n",
        "val_Y = np.array(val_Y)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMCYK-UzCsEz",
        "outputId": "db9ebd9f-c3d7-4240-bd73-dd7e834bc695"
      },
      "cell_type": "code",
      "source": [
        "print(train_X.shape,val_X.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140000, 32, 32, 1) (15209, 32, 32, 1)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta89H7-ZCsEz",
        "outputId": "7cf92d8f-d598-41b6-a494-a2caaa1e5b1f"
      },
      "cell_type": "code",
      "source": [
        "print(train_Y.shape,val_Y.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(140000, 35) (15209, 35)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "tVNgZ2MJCsEz"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding = \"same\", activation='relu', input_shape=(32,32,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(35, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCm7ZuNECsEz",
        "outputId": "27b6a851-2ccb-467f-cdc5-c896ff686f99"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 5, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 35)                4515      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 162851 (636.14 KB)\n",
            "Trainable params: 162851 (636.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Vmn2UU4vCsE0"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDRTr0U1CsE0",
        "outputId": "c1ae86f5-ce1c-40e8-8db0-f246f7bba25f"
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(train_X,train_Y, epochs=50, batch_size=32, validation_data = (val_X, val_Y),  verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4375/4375 [==============================] - 217s 49ms/step - loss: 0.6193 - accuracy: 0.8028 - val_loss: 0.3284 - val_accuracy: 0.8889\n",
            "Epoch 2/50\n",
            "4375/4375 [==============================] - 222s 51ms/step - loss: 0.3456 - accuracy: 0.8827 - val_loss: 0.2851 - val_accuracy: 0.9103\n",
            "Epoch 3/50\n",
            "4375/4375 [==============================] - 214s 49ms/step - loss: 0.3035 - accuracy: 0.8965 - val_loss: 0.2868 - val_accuracy: 0.9007\n",
            "Epoch 4/50\n",
            "4375/4375 [==============================] - 209s 48ms/step - loss: 0.2770 - accuracy: 0.9049 - val_loss: 0.2445 - val_accuracy: 0.9179\n",
            "Epoch 5/50\n",
            "4375/4375 [==============================] - 215s 49ms/step - loss: 0.2589 - accuracy: 0.9090 - val_loss: 0.2743 - val_accuracy: 0.8984\n",
            "Epoch 6/50\n",
            "4375/4375 [==============================] - 211s 48ms/step - loss: 0.2481 - accuracy: 0.9131 - val_loss: 0.2449 - val_accuracy: 0.9153\n",
            "Epoch 7/50\n",
            "4375/4375 [==============================] - 209s 48ms/step - loss: 0.2389 - accuracy: 0.9165 - val_loss: 0.2404 - val_accuracy: 0.9131\n",
            "Epoch 8/50\n",
            "4375/4375 [==============================] - 214s 49ms/step - loss: 0.2296 - accuracy: 0.9187 - val_loss: 0.2271 - val_accuracy: 0.9237\n",
            "Epoch 9/50\n",
            "4375/4375 [==============================] - 209s 48ms/step - loss: 0.2215 - accuracy: 0.9211 - val_loss: 0.2420 - val_accuracy: 0.9149\n",
            "Epoch 10/50\n",
            "4375/4375 [==============================] - 209s 48ms/step - loss: 0.2155 - accuracy: 0.9219 - val_loss: 0.2303 - val_accuracy: 0.9208\n",
            "Epoch 11/50\n",
            "4375/4375 [==============================] - 209s 48ms/step - loss: 0.2123 - accuracy: 0.9232 - val_loss: 0.2372 - val_accuracy: 0.9202\n",
            "Epoch 12/50\n",
            "4375/4375 [==============================] - 208s 48ms/step - loss: 0.2066 - accuracy: 0.9235 - val_loss: 0.2402 - val_accuracy: 0.9184\n",
            "Epoch 13/50\n",
            "4375/4375 [==============================] - 215s 49ms/step - loss: 0.2026 - accuracy: 0.9261 - val_loss: 0.2513 - val_accuracy: 0.9181\n",
            "Epoch 14/50\n",
            "4375/4375 [==============================] - 212s 49ms/step - loss: 0.1984 - accuracy: 0.9275 - val_loss: 0.2476 - val_accuracy: 0.9099\n",
            "Epoch 15/50\n",
            "4375/4375 [==============================] - 213s 49ms/step - loss: 0.1976 - accuracy: 0.9284 - val_loss: 0.2501 - val_accuracy: 0.9110\n",
            "Epoch 16/50\n",
            "4375/4375 [==============================] - 211s 48ms/step - loss: 0.1905 - accuracy: 0.9303 - val_loss: 0.2394 - val_accuracy: 0.9202\n",
            "Epoch 17/50\n",
            "4375/4375 [==============================] - 212s 48ms/step - loss: 0.1902 - accuracy: 0.9301 - val_loss: 0.2506 - val_accuracy: 0.9151\n",
            "Epoch 18/50\n",
            "4375/4375 [==============================] - 212s 48ms/step - loss: 0.1891 - accuracy: 0.9303 - val_loss: 0.2399 - val_accuracy: 0.9197\n",
            "Epoch 19/50\n",
            " 971/4375 [=====>........................] - ETA: 2:41 - loss: 0.1726 - accuracy: 0.9354"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3dYjWw7aCsE0"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training Accuracy vs Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ydRSMOhuCsE0"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ik8qMtneCsE0"
      },
      "cell_type": "markdown",
      "source": [
        "## Recognition and Post-Processing\n",
        "1. The sort contours function is used to get the correct order of individual characters for correct output extraction. In this case for extracting a single word, a left to right sorting of individual characters is needed.\n",
        "2. The get letters function fetches the list of letters and get word function gets the individual word."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "qBrsRsUHCsE0"
      },
      "cell_type": "code",
      "source": [
        "def sort_contours(cnts, method=\"left-to-right\"):\n",
        "    reverse = False\n",
        "    i = 0\n",
        "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
        "        reverse = True\n",
        "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
        "        i = 1\n",
        "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "    key=lambda b:b[1][i], reverse=reverse))\n",
        "    # return the list of sorted contours and bounding boxes\n",
        "    return (cnts, boundingBoxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "xKrfgREaCsE0"
      },
      "cell_type": "code",
      "source": [
        "def get_letters(img):\n",
        "    letters = []\n",
        "    image = cv2.imread(img)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY_INV)\n",
        "    dilated = cv2.dilate(thresh1, None, iterations=2)\n",
        "\n",
        "    cnts = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
        "    # loop over the contours\n",
        "    for c in cnts:\n",
        "        if cv2.contourArea(c) > 10:\n",
        "            (x, y, w, h) = cv2.boundingRect(c)\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        roi = gray[y:y + h, x:x + w]\n",
        "        thresh = cv2.threshold(roi, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "        thresh = cv2.resize(thresh, (32, 32), interpolation = cv2.INTER_CUBIC)\n",
        "        thresh = thresh.astype(\"float32\") / 255.0\n",
        "        thresh = np.expand_dims(thresh, axis=-1)\n",
        "        thresh = thresh.reshape(1,32,32,1)\n",
        "        ypred = model.predict(thresh)\n",
        "        ypred = LB.inverse_transform(ypred)\n",
        "        [x] = ypred\n",
        "        letters.append(x)\n",
        "    return letters, image\n",
        "\n",
        "#plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yqm2WAzaCsE0"
      },
      "cell_type": "code",
      "source": [
        "def get_word(letter):\n",
        "    word = \"\".join(letter)\n",
        "    return word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yC3HqnbSCsE0"
      },
      "cell_type": "code",
      "source": [
        "letter,image = get_letters(\"../input/handwriting-recognition/train_v2/train/TRAIN_00003.jpg\")\n",
        "word = get_word(letter)\n",
        "print(word)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_1OAbKqBCsE1"
      },
      "cell_type": "code",
      "source": [
        "letter,image = get_letters(\"../input/handwriting-recognition/train_v2/train/TRAIN_00023.jpg\")\n",
        "word = get_word(letter)\n",
        "print(word)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "RX55r-B8CsE1"
      },
      "cell_type": "code",
      "source": [
        "letter,image = get_letters(\"../input/handwriting-recognition/train_v2/train/TRAIN_00030.jpg\")\n",
        "word = get_word(letter)\n",
        "print(word)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UNwH1wq_CsE1"
      },
      "cell_type": "code",
      "source": [
        "letter,image = get_letters(\"../input/handwriting-recognition/validation_v2/validation/VALIDATION_0005.jpg\")\n",
        "word = get_word(letter)\n",
        "print(word)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3PN_OwibCsE1"
      },
      "cell_type": "code",
      "source": [
        "letter,image = get_letters(\"../input/handwriting-recognition/test_v2/test/TEST_0007.jpg\")\n",
        "word = get_word(letter)\n",
        "print(word)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aS9anSlbCsE1"
      },
      "cell_type": "markdown",
      "source": [
        "## Drawbacks\n",
        "1. The recognition part is dependent on the contour detection code, so if the opencv library is not able to find the character contour, then this method will fail.\n",
        "2. There could be a lot of variation in a single handwritten letter in terms of writing style, therefore a lot more examples are needed for training this model.\n",
        "3. This model will not work for connected texts like a cursive handwritten word."
      ]
    },
    {
      "metadata": {
        "id": "z4qpTdqECsE1"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "This notebook is an illustration of how a character segmentation and classification approach can be used for offline handwritten text extraction. In order to improve the model, the model should be trained on the complete dataset, this notebook was trained on slightly less number of images due to session constraints. Also, for applying this method to a complete paragraph, following approach can be used, **line segmentation >> word segmentation >> character segmentation >> classification >> post-processing**."
      ]
    },
    {
      "metadata": {
        "id": "Fq8O8gYPCsE1"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "1. [https://www.pyimagesearch.com/2020/08/24/ocr-handwriting-recognition-with-opencv-keras-and-tensorflow/](http://)\n",
        "2. [https://www.pyimagesearch.com/2015/04/20/sorting-contours-using-python-and-opencv/](http://)"
      ]
    },
    {
      "metadata": {
        "id": "jplvaFtnCsE1"
      },
      "cell_type": "markdown",
      "source": [
        "If you liked this notebook, then do **Upvote** as it will keep me motivated in creating such kernels ahead. **Thanks!!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Offline Handwritten Text OCR",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}